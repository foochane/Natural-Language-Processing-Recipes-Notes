{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "You want to know the architecture and NLP pipeline to build a search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6-1 Preprocessing\n",
    "Whenever the user enters the search query, it is passed on to the NLP\n",
    "preprocessing pipeline:\n",
    "\n",
    "1. Removal of noise and stop words(消除噪音和停顿词)\n",
    "\n",
    "2. Tokenization（语意切分）\n",
    "\n",
    "3. Stemming\n",
    "\n",
    "4. Lemmatization（词形还原）\n",
    "\n",
    "## Step 6-2 The entity extraction model\n",
    "Output from the above pipeline is fed into the entity extraction model.\n",
    "We can build the customized entity recognition model by using any of the\n",
    "libraries like StanfordNER or NLTK.\n",
    "\n",
    "Or you can build an entity recognition model from scratch using\n",
    "conditional random fields or Markov models.\n",
    "\n",
    "For example, suppose we are building a search engine for an\n",
    "e-commerce giant. Below are entities that we can train the model on:\n",
    "\n",
    "• Gender\n",
    "\n",
    "• Color\n",
    "\n",
    "• Brand\n",
    "\n",
    "• Product Category\n",
    "\n",
    "• Product Type\n",
    "\n",
    "• Price\n",
    "\n",
    "• Size\n",
    "\n",
    "Also, we can build named entity disambiguation using deep\n",
    "learning frameworks like RNN and LSTM. This is very important for the\n",
    "entities extractor to understand the content in which the entities are\n",
    "used. For example, pink can be a color or a brand. NED helps in such\n",
    "disambiguation.\n",
    "\n",
    "NERD Model building steps:\n",
    "\n",
    "• Data cleaning and preprocessing\n",
    "\n",
    "• Training NER Model\n",
    "\n",
    "• Testing and Validation\n",
    "\n",
    "• Deployment\n",
    "\n",
    "Ways to train/build NERD model:\n",
    "\n",
    "• Named Entity Recognition and Disambiguation\n",
    "\n",
    "• Stanford NER with customization\n",
    "\n",
    "• Recurrent Neural Network (RNN) – LSTM (Long ShortTerm Memory) to use context for disambiguation\n",
    "\n",
    "• Joint Named Entity Recognition and Disambiguation\n",
    "\n",
    "##Step 6-3 Query enhancement/expansion\n",
    "It is very important to understand the possible synonyms of the entities to\n",
    "make sure search results do not miss out on potential relevance. Say, for\n",
    "example, men’s shoes can also be called as male shoes, men’s sports shoes,\n",
    "men’s formal shoes, men’s loafers, men’s sneakers.\n",
    "\n",
    "Use locally-trained word embedding (using Word2Vec / GloVe\n",
    "Model ) to achieve this.\n",
    "\n",
    "## Step 6-4 Use a search platform\n",
    "Search platforms such as Solr or Elastic Search have major features that\n",
    "include full-text search hit highlighting, faceted search, real-time indexing,\n",
    "dynamic clustering, and database integration. This is not related to\n",
    "NLP; as an end-to-end application point of view, we have just given an\n",
    "introduction of what this is.\n",
    "\n",
    "## Step 6-5 Learning to rank\n",
    "Once the search results are fetched from Solr or Elastic Search, they should\n",
    "be ranked based on the user preferences using the past behaviors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
