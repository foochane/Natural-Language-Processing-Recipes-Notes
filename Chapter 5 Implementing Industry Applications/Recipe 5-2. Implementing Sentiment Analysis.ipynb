{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "We want to implement sentiment analysis.\n",
    "## Solution\n",
    "The simplest way to do this by using the TextBlob or vaderSentiment\n",
    "library. Since we have used TextBlob previously, now let us use vader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-1 Understanding/defining business problem\n",
    "Understand how products are doing in the market. How are customers\n",
    "reacting to a particular product? What is the consumer’s sentiment\n",
    "across products? Many more questions like these can be answered using\n",
    "sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-2 Identifying potential data sources, collection, and understanding\n",
    "We have a dataset for Amazon food reviews. Let’s use that data and extract\n",
    "insight out of it. \n",
    "\n",
    "You can download the data from the link below:\n",
    "\n",
    "https://www.kaggle.com/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#Read the data\n",
    "df = pd.read_csv('D:\\\\workspace\\\\data\\\\amazon-fine-food-reviews\\\\Reviews.csv')\n",
    "# Look at the top 5 rows of the data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      "Id                        568454 non-null int64\n",
      "ProductId                 568454 non-null object\n",
      "UserId                    568454 non-null object\n",
      "ProfileName               568438 non-null object\n",
      "HelpfulnessNumerator      568454 non-null int64\n",
      "HelpfulnessDenominator    568454 non-null int64\n",
      "Score                     568454 non-null int64\n",
      "Time                      568454 non-null int64\n",
      "Summary                   568428 non-null object\n",
      "Text                      568454 non-null object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Understand the data types of the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Good Quality Dog Food\n",
       "1        Not as Advertised\n",
       "2    \"Delight\" says it all\n",
       "3           Cough Medicine\n",
       "4              Great taffy\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the summary of the reviews.\n",
    "df.Summary.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have bought several of the Vitality canned d...\n",
       "1    Product arrived labeled as Jumbo Salted Peanut...\n",
       "2    This is a confection that has been around a fe...\n",
       "3    If you are looking for the secret ingredient i...\n",
       "4    Great taffy at a great price.  There was a wid...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the description of the reviews\n",
    "df.Text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-3 Text preprocessing\n",
    "We all know the importance of this step. Let us perform a preprocessing\n",
    "task as discussed in Chapter 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i have bought several of the vitality canned d...\n",
       "1    product arrived labeled as jumbo salted peanut...\n",
       "2    this is a confection that has been around a fe...\n",
       "3    if you are looking for the secret ingredient i...\n",
       "4    great taffy at a great price there was a wide ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "# Lower casing and removing punctuations\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x.lower() for\n",
    "x in x.split()))\n",
    "df['Text'] = df['Text'].str.replace('[^\\w\\s]',\"\")\n",
    "df.Text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of stop words\n",
    "stop = stopwords.words('english')\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x for x in\n",
    "x.split() if x not in stop))\n",
    "df.Text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spelling correction\n",
    "df['Text'] = df['Text'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "df.Text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df.Text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-4 Exploratory data analysis\n",
    "This step is not connected anywhere in predicting sentiments; what we are\n",
    "trying to do here is to dig deeper into the data and understand it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame \"reviews\" to perform exploratory data analysis upon that\n",
    "reviews = df\n",
    "\n",
    "# Dropping null values\n",
    "reviews.dropna(inplace=True)\n",
    "\n",
    "# The histogram reveals this dataset is highly unbalanced\n",
    "towards high rating.\n",
    "reviews.Score.hist(bins=5,grid=False)\n",
    "plt.show()\n",
    "print(reviews.groupby('Score').count().Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make it balanced data, we sampled each score by the lowest\n",
    "n-count from above. (i.e. 29743 reviews scored as '2')\n",
    "score_1 = reviews[reviews['Score'] == 1].sample(n=29743)\n",
    "score_2 = reviews[reviews['Score'] == 2].sample(n=29743)\n",
    "score_3 = reviews[reviews['Score'] == 3].sample(n=29743)\n",
    "score_4 = reviews[reviews['Score'] == 4].sample(n=29743)\n",
    "score_5 = reviews[reviews['Score'] == 5].sample(n=29743)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we recreate a 'balanced' dataset.\n",
    "reviews_sample = pd.concat([score_1,score_2,score_3,score_4,score_5],axis=0)\n",
    "reviews_sample.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this dataset if you are training your own sentiment\n",
    "classifier from scratch. And to do this. you can follow the same steps as in\n",
    "text classification (Recipe 5-1). Here our target variable would be positive,\n",
    "negative, and neutral created using score.\n",
    "\n",
    "• Score <= 2: Negative\n",
    "\n",
    "• Score = 3: Neutral\n",
    "\n",
    "• Score > =4: Positive\n",
    "\n",
    "Having said that, let’s get back to our exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing count by 'Score' to check dataset is now balanced.\n",
    "print(reviews_sample.groupby('Score').count().Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a word cloud looking at the 'Summary' text\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Wordcloud function's input needs to be a single string of text.\n",
    "# Here I'm concatenating all Summaries into a single string.\n",
    "# similarly you can build for Text column\n",
    "reviews_str = reviews_sample.Summary.str.cat()\n",
    "wordcloud = WordCloud(background_color='white').\n",
    "generate(reviews_str)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's split the data into Negative (Score is 1 or 2) and Positive (4 or #5) Reviews.\n",
    "negative_reviews = reviews_sample[reviews_sample['Score'].isin([1,2]) ]\n",
    "positive_reviews = reviews_sample[reviews_sample['Score'].isin([4,5]) ]\n",
    "\n",
    "# Transform to single string\n",
    "negative_reviews_str = negative_reviews.Summary.str.cat()\n",
    "positive_reviews_str = positive_reviews.Summary.str.cat()\n",
    "\n",
    "# Create wordclouds\n",
    "wordcloud_negative = WordCloud(background_color='white').generate(negative_reviews_str)\n",
    "wordcloud_positive = WordCloud(background_color='white').generate(positive_reviews_str)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.imshow(wordcloud_negative,interpolation='bilinear')\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title('Reviews with Negative Scores',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = fig.add_subplot(212)\n",
    "ax2.imshow(wordcloud_positive,interpolation='bilinear')\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title('Reviews with Positive Scores',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-5 Feature engineering\n",
    "This step is not required as we are not building the model from scratch;\n",
    "rather we are using the pretrained model from the library vaderSentiment.\n",
    "\n",
    "If you want to build the model from scratch, you can leverage the\n",
    "above positive and negative classes created while exploring as a target\n",
    "variable and then training the model. You can follow the same steps as text\n",
    "classification explained in Recipe 5-1 to build a sentiment classifier from\n",
    "scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-6 Sentiment scores\n",
    "Sentiment Analysis: Pretrained model takes the input from the text\n",
    "description and outputs the sentiment score ranging from -1 to +1 for each\n",
    "sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Function for getting the sentiment\n",
    "cp = sns.color_palette()\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Generating sentiment for all the sentence present in the dataset\n",
    "emptyline=[]\n",
    "for row in df['Text']:\n",
    "    vs=analyzer.polarity_scores(row)\n",
    "    emptyline.append(vs)\n",
    "\n",
    "# Creating new dataframe with sentiments\n",
    "df_sentiments=pd.DataFrame(emptyline)\n",
    "df_sentiments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the sentiments back to reviews dataframe\n",
    "df_c = pd.concat([df.reset_index(drop=True), d], axis=1)\n",
    "df_c.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scores into positive and negetive sentiments using some threshold\n",
    "df_c['Sentiment'] = np.where(df_c['compound'] >= 0 , 'Positive','Negative')\n",
    "df_c.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-7 Business insights\n",
    "Let’s see how the overall sentiment is using the sentiment we generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=df_c['Sentiment'].value_counts()\n",
    "result.plot(kind='bar', rot=0,color='br')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just took a sample of 1000 reviews and completed sentiment\n",
    "analysis. If you look, more than 900 (>90%) reviews are positive, which is\n",
    "really good for any business.\n",
    "\n",
    "We can also group by-products, that is, sentiments by-products to\n",
    "understand the high-level customer feedback against products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample code snippet\n",
    "result=df_c.groupby('ProductId')['Sentiment'].value_counts().unstack()\n",
    "result[['Negative','Positive']].plot(kind='bar',rot=0,color='rb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can analyze sentiments by month using the time column\n",
    "and many other such attributes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
