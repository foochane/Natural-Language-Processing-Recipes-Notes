{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题\n",
    "爬取IMDB的电影"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 安装必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\workspace\\python\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\workspace\\python\\anaconda3\\lib\\site-packages (from bs4) (4.6.0)\n",
      "Requirement already satisfied: requests in d:\\workspace\\python\\anaconda3\\lib\\site-packages (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\workspace\\python\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in d:\\workspace\\python\\anaconda3\\lib\\site-packages (from requests) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in d:\\workspace\\python\\anaconda3\\lib\\site-packages (from requests) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspace\\python\\anaconda3\\lib\\site-packages (from requests) (2017.7.27.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4\n",
    "! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 导入库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from ipywidgets import FloatProgress\n",
    "from time import sleep\n",
    "from IPython.display import display\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Identify the url to extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.imdb.com/chart/top?ref_=nv_mv_250_6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Request the url and download the content using beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(url)\n",
    "c = result.content\n",
    "soup = BeautifulSoup(c,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Understand the website page structure to extract the required information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 Use beautiful soup to extract and parse the data from HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374f1eb749e94e1981a1eb3019cac1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = soup.find('div',{'class':'article'})\n",
    "\n",
    "# Create empty lists to append the extracted data.\n",
    "moviename = []\n",
    "cast = []\n",
    "description = []\n",
    "rating = []\n",
    "ratingoutof = []\n",
    "year = []\n",
    "genre = []\n",
    "movielength = []\n",
    "rot_audscore = []\n",
    "rot_avgrating = []\n",
    "rot_users = []\n",
    "\n",
    "# Extracting the required data from the html soup.\n",
    "rgx = re.compile('[%s]' % '()')\n",
    "f = FloatProgress(min=0, max=250)\n",
    "display(f)\n",
    "for row,i in zip(summary.find('table').findAll('tr'),range(len(summary.find('table').findAll('tr')))):\n",
    "    for sitem in row.findAll('span',{'class':'secondaryInfo'}):\n",
    "        s = sitem.find(text=True)\n",
    "        year.append(rgx.sub(\"\", s))\n",
    "    for ritem in row.findAll('td',{'class':'ratingColumn imdbRating'}):\n",
    "        for iget in ritem.findAll('strong'):\n",
    "            rating.append(iget.find(text=True))\n",
    "            ratingoutof.append(iget.get('title').split(' ', 4)[3])\n",
    "    for item in row.findAll('td',{'class':'titleColumn'}):\n",
    "        for href in item.findAll('a',href=True):\n",
    "            moviename.append(href.find(text=True))\n",
    "            rurl = 'https://www.rottentomatoes.com/m/'+ href.find(text=True)\n",
    "            try:\n",
    "                rresult = requests.get(rurl)\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                status_code = \"Connection refused\"\n",
    "            rc = rresult.content\n",
    "            rsoup = BeautifulSoup(rc)\n",
    "            try:\n",
    "                rot_audscore.append(rsoup.find('div',\n",
    "                {'class':'meter-value'}).find('span',\n",
    "                {'class':'superPageFontColor'}).text)\n",
    "                rot_avgrating.append(rsoup.find('div',\n",
    "                {'class':'audience-info hidden-xs superPageFontColor'}).find('div').contents[2].strip())\n",
    "                rot_users.append(rsoup.find('div',\n",
    "                {'class':'audience-info hidden-xs superPageFontColor'}).contents[3].contents[2].strip())\n",
    "            except AttributeError:\n",
    "                rot_audscore.append(\"\")\n",
    "                rot_avgrating.append(\"\")\n",
    "                rot_users.append(\"\")\n",
    "            cast.append(href.get('title'))\n",
    "            imdb = \"http://www.imdb.com\" + href.get('href')\n",
    "            try:\n",
    "                iresult = requests.get(imdb)\n",
    "                ic = iresult.content\n",
    "                isoup = BeautifulSoup(ic)\n",
    "                description.append(isoup.find('div',\n",
    "                {'class':'summary_text'}).find(text=True).strip())\n",
    "                genre.append(isoup.find('span',{'class':'itemprop'}).find(text=True))\n",
    "#                 movielength.append(isoup.find('time',{'itemprop':'duration'}).find(text=True).strip())\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                description.append(\"\")\n",
    "                genre.append(\"\")\n",
    "                movielength.append(\"\")\n",
    "    sleep(.1)\n",
    "    f.value = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 Convert lists to data frame and you can perform the analysis that meets the business requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to pandas series\n",
    "moviename = Series(moviename)\n",
    "cast = Series(cast)\n",
    "description = Series(description)\n",
    "rating = Series(rating)\n",
    "ratingoutof = Series(ratingoutof)\n",
    "year = Series(year)\n",
    "genre = Series(genre)\n",
    "movielength = Series(movielength)\n",
    "rot_audscore = Series(rot_audscore)\n",
    "rot_avgrating = Series(rot_avgrating)\n",
    "rot_users = Series(rot_users)\n",
    "# creating dataframe and doing analysis\n",
    "imdb_df = pd.concat([moviename,year,description,genre,\n",
    "movielength,cast,rating,ratingoutof,\n",
    "rot_audscore,rot_avgrating,rot_users],axis=1)\n",
    "imdb_df.columns = ['moviename','year','description','genre',\n",
    "    'movielength','cast','imdb_rating',\n",
    "    'imdb_ratingbasedon','tomatoes_audscore',\n",
    "    'tomatoes_rating','tomatoes_ratingbasedon']\n",
    "imdb_df['rank'] = imdb_df.index + 1\n",
    "imdb_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 Download the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the file as CSV.\n",
    "imdb_df.to_csv(\"imdbdataexport.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
