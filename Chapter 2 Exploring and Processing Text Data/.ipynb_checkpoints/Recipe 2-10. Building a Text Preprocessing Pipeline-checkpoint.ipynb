{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "You want to build an end-to-end text preprocessing pipeline. Whenever\n",
    "you want to do preprocessing for any NLP application, you can directly\n",
    "plug in data to this pipeline function and get the required clean text data as\n",
    "the output.\n",
    "## Solution\n",
    "The simplest way to do this by creating the custom function with all the\n",
    "techniques learned so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10-1 Read/create the text data\n",
    "Letâ€™s create a list of strings and assign it to a variable. Maybe a tweet sample:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sample= \"How to take control of your #debt https://personal.vanguard.com/us/insights/saving-investing/debt-management.#Best advice for #family #financial #success(@PrepareToWin)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10-2 Process the text\n",
    "Execute the below function to process the tweet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRow(row):\n",
    "    import re\n",
    "    import nltk\n",
    "    from textblob import TextBlob\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from textblob import Word\n",
    "    from nltk.util import ngrams\n",
    "    import re\n",
    "    from wordcloud import WordCloud, STOPWORDS\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    tweet = row\n",
    "    #Lower case\n",
    "    tweet.lower()\n",
    "    #Removes unicode strings like \"\\u002c\" and \"x96\"\n",
    "    tweet = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r\"\", tweet)\n",
    "    tweet = re.sub(r'[^\\x00-\\x7f]',r\"\",tweet)\n",
    "    #convert any url to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert any @Username to \"AT_USER\"\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    tweet = re.sub('[\\n]+', ' ', tweet)\n",
    "    #Remove not alphanumeric symbols white spaces\n",
    "    tweet = re.sub(r'[^\\w]', ' ', tweet)\n",
    "    #Removes hastag in front of a word \"\"\"\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #Remove :( or :)\n",
    "    tweet = tweet.replace(':)',\"\")\n",
    "    tweet = tweet.replace(':(',\"\")\n",
    "    #remove numbers\n",
    "    tweet = \"\".join([i for i in tweet if not i.isdigit()])\n",
    "    #remove multiple exclamation\n",
    "    tweet = re.sub(r\"(\\!)\\1+\", ' ', tweet)\n",
    "    #remove multiple question marks\n",
    "    tweet = re.sub(r\"(\\?)\\1+\", ' ', tweet)\n",
    "    #remove multistop\n",
    "    tweet = re.sub(r\"(\\.)\\1+\", ' ', tweet)\n",
    "    #lemma\n",
    "    from textblob import Word\n",
    "    tweet =\" \".join([Word(word).lemmatize() for word in tweet.\n",
    "    split()])\n",
    "    #stemmer\n",
    "    #st = PorterStemmer()\n",
    "    #tweet=\" \".join([st.stem(word) for word in tweet.split()])\n",
    "    \n",
    "    #Removes emoticons from text\n",
    "#     tweet = re.sub(':\\)|;\\)|:-\\)|\\(-:|:-D|=D|:P|xD|X-p|\\^\\^|:-*|\\^\\.\\^|\\^\\-\\^|\\^\\_\\^|\\,-\\)|\\)-:|:\\'\\(|:\\(|:-\\(|:\\S|T\\.T|\\.\\_\\.|:<|:-\\S|:-<|\\*\\-\\*|:O|=O|=\\-O|O\\.o|XO|O\\_O|:-\\@|=/|:/|X\\-\\(|>\\.<|>=\\(|D:', \", tweet)\n",
    "    \n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    row = tweet\n",
    "    return row\n",
    "\n",
    "#call the function with your data\n",
    "processRow(tweet_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
