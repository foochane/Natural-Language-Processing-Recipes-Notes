{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用的库：NLTK, SpaCy, and TextBlob."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "You want to do tokenization.\n",
    "## Solution\n",
    "The simplest way to do this is by using the TextBlob library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6-1 Read/create the text data\n",
    "Let’s create a list of strings and assign it to a variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet\n",
      "0                        This is introduction to NLP\n",
      "1               It is likely to be useful to people \n",
      "2             Machine learning is the new electrcity\n",
      "3  There would be less hype around AI and more ac...\n",
      "4                           python is the best tool!\n",
      "5                                R is good langauage\n",
      "6                                   I like this book\n",
      "7                        I want more books like this\n"
     ]
    }
   ],
   "source": [
    "text=['This is introduction to NLP',\n",
    "      'It is likely to be useful to people ',\n",
    "      'Machine learning is the new electrcity', \n",
    "      'There would be less hype around AI and more action going  forward',\n",
    "      'python is the best tool!','R is good langauage', \n",
    "      'I like this book','I want more books like this']\n",
    "\n",
    "#convert list to dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'tweet':text})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6-2 Execute below code on the text data\n",
    "The result of tokenization is a list of tokens:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using textblob\n",
    "from textblob import TextBlob\n",
    "TextBlob(df['tweet'][3]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using NLTK\n",
    "import nltk\n",
    "#create data\n",
    "mystring = \"My favorite animal is cat\"\n",
    "nltk.word_tokenize(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'favorite', 'animal', 'is', 'cat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using split function from python\n",
    "mystring.split()\n",
    "#output\n",
    "['My', 'favorite', 'animal', 'is', 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
